{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7c036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files to be included: ['/home/dream-lab/project/spell_correction/.data/text/59000.json', '/home/dream-lab/project/spell_correction/.data/text/31000.json', '/home/dream-lab/project/spell_correction/.data/text/69000.json', '/home/dream-lab/project/spell_correction/.data/text/34000.json', '/home/dream-lab/project/spell_correction/.data/text/101000.json', '/home/dream-lab/project/spell_correction/.data/text/143000.json', '/home/dream-lab/project/spell_correction/.data/text/122000.json', '/home/dream-lab/project/spell_correction/.data/text/108000.json', '/home/dream-lab/project/spell_correction/.data/text/14000.json', '/home/dream-lab/project/spell_correction/.data/text/43000.json', '/home/dream-lab/project/spell_correction/.data/text/90000.json', '/home/dream-lab/project/spell_correction/.data/text/107000.json', '/home/dream-lab/project/spell_correction/.data/text/56000.json', '/home/dream-lab/project/spell_correction/.data/text/49000.json', '/home/dream-lab/project/spell_correction/.data/text/55000.json', '/home/dream-lab/project/spell_correction/.data/text/20000.json', '/home/dream-lab/project/spell_correction/.data/text/28000.json', '/home/dream-lab/project/spell_correction/.data/text/106000.json', '/home/dream-lab/project/spell_correction/.data/text/4000.json', '/home/dream-lab/project/spell_correction/.data/text/70000.json', '/home/dream-lab/project/spell_correction/.data/text/62000.json', '/home/dream-lab/project/spell_correction/.data/text/39000.json', '/home/dream-lab/project/spell_correction/.data/text/33000.json', '/home/dream-lab/project/spell_correction/.data/text/103000.json', '/home/dream-lab/project/spell_correction/.data/text/61000.json', '/home/dream-lab/project/spell_correction/.data/text/11000.json', '/home/dream-lab/project/spell_correction/.data/text/137000.json', '/home/dream-lab/project/spell_correction/.data/text/87000.json', '/home/dream-lab/project/spell_correction/.data/text/17000.json', '/home/dream-lab/project/spell_correction/.data/text/127000.json', '/home/dream-lab/project/spell_correction/.data/text/124000.json', '/home/dream-lab/project/spell_correction/.data/text/65000.json', '/home/dream-lab/project/spell_correction/.data/text/48000.json', '/home/dream-lab/project/spell_correction/.data/text/50000.json', '/home/dream-lab/project/spell_correction/.data/text/94000.json', '/home/dream-lab/project/spell_correction/.data/text/52000.json', '/home/dream-lab/project/spell_correction/.data/text/138000.json', '/home/dream-lab/project/spell_correction/.data/text/66000.json', '/home/dream-lab/project/spell_correction/.data/text/7000.json', '/home/dream-lab/project/spell_correction/.data/text/134000.json', '/home/dream-lab/project/spell_correction/.data/text/123000.json', '/home/dream-lab/project/spell_correction/.data/text/8000.json', '/home/dream-lab/project/spell_correction/.data/text/24000.json', '/home/dream-lab/project/spell_correction/.data/text/116000.json', '/home/dream-lab/project/spell_correction/.data/text/19000.json', '/home/dream-lab/project/spell_correction/.data/text/125000.json', '/home/dream-lab/project/spell_correction/.data/text/131000.json', '/home/dream-lab/project/spell_correction/.data/text/79000.json', '/home/dream-lab/project/spell_correction/.data/text/104000.json', '/home/dream-lab/project/spell_correction/.data/text/118000.json', '/home/dream-lab/project/spell_correction/.data/text/84000.json', '/home/dream-lab/project/spell_correction/.data/text/60000.json', '/home/dream-lab/project/spell_correction/.data/text/53000.json', '/home/dream-lab/project/spell_correction/.data/text/5000.json', '/home/dream-lab/project/spell_correction/.data/text/76000.json', '/home/dream-lab/project/spell_correction/.data/text/73000.json', '/home/dream-lab/project/spell_correction/.data/text/1000.json', '/home/dream-lab/project/spell_correction/.data/text/35000.json', '/home/dream-lab/project/spell_correction/.data/text/6000.json', '/home/dream-lab/project/spell_correction/.data/text/93000.json', '/home/dream-lab/project/spell_correction/.data/text/92000.json', '/home/dream-lab/project/spell_correction/.data/text/67000.json', '/home/dream-lab/project/spell_correction/.data/text/88000.json', '/home/dream-lab/project/spell_correction/.data/text/105000.json', '/home/dream-lab/project/spell_correction/.data/text/16000.json', '/home/dream-lab/project/spell_correction/.data/text/36000.json', '/home/dream-lab/project/spell_correction/.data/text/21000.json', '/home/dream-lab/project/spell_correction/.data/text/78000.json', '/home/dream-lab/project/spell_correction/.data/text/18000.json', '/home/dream-lab/project/spell_correction/.data/text/64000.json', '/home/dream-lab/project/spell_correction/.data/text/100000.json', '/home/dream-lab/project/spell_correction/.data/text/97000.json', '/home/dream-lab/project/spell_correction/.data/text/140000.json', '/home/dream-lab/project/spell_correction/.data/text/10000.json', '/home/dream-lab/project/spell_correction/.data/text/135000.json', '/home/dream-lab/project/spell_correction/.data/text/12000.json', '/home/dream-lab/project/spell_correction/.data/text/109000.json', '/home/dream-lab/project/spell_correction/.data/text/41000.json', '/home/dream-lab/project/spell_correction/.data/text/130000.json', '/home/dream-lab/project/spell_correction/.data/text/42000.json', '/home/dream-lab/project/spell_correction/.data/text/38000.json', '/home/dream-lab/project/spell_correction/.data/text/71000.json', '/home/dream-lab/project/spell_correction/.data/text/23000.json', '/home/dream-lab/project/spell_correction/.data/text/139000.json', '/home/dream-lab/project/spell_correction/.data/text/83000.json', '/home/dream-lab/project/spell_correction/.data/text/75000.json', '/home/dream-lab/project/spell_correction/.data/text/119000.json', '/home/dream-lab/project/spell_correction/.data/text/37000.json', '/home/dream-lab/project/spell_correction/.data/text/45000.json', '/home/dream-lab/project/spell_correction/.data/text/2000.json', '/home/dream-lab/project/spell_correction/.data/text/110000.json', '/home/dream-lab/project/spell_correction/.data/text/27000.json', '/home/dream-lab/project/spell_correction/.data/text/117000.json', '/home/dream-lab/project/spell_correction/.data/text/29000.json', '/home/dream-lab/project/spell_correction/.data/text/115000.json', '/home/dream-lab/project/spell_correction/.data/text/13000.json', '/home/dream-lab/project/spell_correction/.data/text/54000.json', '/home/dream-lab/project/spell_correction/.data/text/129000.json', '/home/dream-lab/project/spell_correction/.data/text/120000.json', '/home/dream-lab/project/spell_correction/.data/text/91000.json', '/home/dream-lab/project/spell_correction/.data/text/126000.json', '/home/dream-lab/project/spell_correction/.data/text/47000.json', '/home/dream-lab/project/spell_correction/.data/text/9000.json', '/home/dream-lab/project/spell_correction/.data/text/82000.json', '/home/dream-lab/project/spell_correction/.data/text/63000.json', '/home/dream-lab/project/spell_correction/.data/text/22000.json', '/home/dream-lab/project/spell_correction/.data/text/3000.json', '/home/dream-lab/project/spell_correction/.data/text/132000.json', '/home/dream-lab/project/spell_correction/.data/text/26000.json', '/home/dream-lab/project/spell_correction/.data/text/85000.json', '/home/dream-lab/project/spell_correction/.data/text/133000.json', '/home/dream-lab/project/spell_correction/.data/text/111000.json', '/home/dream-lab/project/spell_correction/.data/text/141000.json', '/home/dream-lab/project/spell_correction/.data/text/142000.json', '/home/dream-lab/project/spell_correction/.data/text/68000.json', '/home/dream-lab/project/spell_correction/.data/text/72000.json', '/home/dream-lab/project/spell_correction/.data/text/15000.json', '/home/dream-lab/project/spell_correction/.data/text/95000.json', '/home/dream-lab/project/spell_correction/.data/text/121000.json', '/home/dream-lab/project/spell_correction/.data/text/58000.json', '/home/dream-lab/project/spell_correction/.data/text/30000.json', '/home/dream-lab/project/spell_correction/.data/text/136000.json', '/home/dream-lab/project/spell_correction/.data/text/77000.json', '/home/dream-lab/project/spell_correction/.data/text/89000.json', '/home/dream-lab/project/spell_correction/.data/text/25000.json', '/home/dream-lab/project/spell_correction/.data/text/96000.json', '/home/dream-lab/project/spell_correction/.data/text/102000.json', '/home/dream-lab/project/spell_correction/.data/text/44000.json', '/home/dream-lab/project/spell_correction/.data/text/98000.json', '/home/dream-lab/project/spell_correction/.data/text/99000.json', '/home/dream-lab/project/spell_correction/.data/text/143747.json', '/home/dream-lab/project/spell_correction/.data/text/113000.json', '/home/dream-lab/project/spell_correction/.data/text/128000.json', '/home/dream-lab/project/spell_correction/.data/text/74000.json', '/home/dream-lab/project/spell_correction/.data/text/51000.json', '/home/dream-lab/project/spell_correction/.data/text/57000.json', '/home/dream-lab/project/spell_correction/.data/text/32000.json', '/home/dream-lab/project/spell_correction/.data/text/112000.json', '/home/dream-lab/project/spell_correction/.data/text/40000.json', '/home/dream-lab/project/spell_correction/.data/text/81000.json', '/home/dream-lab/project/spell_correction/.data/text/114000.json', '/home/dream-lab/project/spell_correction/.data/text/46000.json', '/home/dream-lab/project/spell_correction/.data/text/86000.json', '/home/dream-lab/project/spell_correction/.data/text/80000.json']\n",
      "\n",
      "\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, Encoding, decoders\n",
    "from pathlib import Path\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"<UNK>\", ignore_merges=False))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()\n",
    "\n",
    "trainer = trainers.BpeTrainer(special_tokens=[\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"], vocab_size=4096)\n",
    "\n",
    "files = [str(i.absolute().resolve()) for i in Path(\"../../.data/text\").iterdir() if i.is_file() and i.name.endswith(\".json\")]\n",
    "print(f\"files to be included: {files}\")\n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "tokenizer.save(\"../../config/output_tokenizer.json\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4adfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '▁ئىنسانلار', '▁ئادەم', 'لەر', '▁بىلەن', '▁ئادەم', '،', '▁ق', 'اسى', 'م', '▁ھا', 'شى', 'م', 'غا', '▁', '‹', 'يا', 'خشى', 'مۇ', 'سىز', '»', '▁دى', 'دى.', '▁ھا', 'شى', 'م', ':', '▁مەن', '▁ياخشى،', '▁ئۆزىڭىز', 'چۇ', '؟', '▁دې', 'دى.', '▁يەنە', '▁باشقا', '▁مى', 'سال', 'لاردىن', '▁گۈزەل', 'لىك', '،', '▁ياخشى', 'لىق،', '▁ئەس', 'كى', 'لىك', '،', '▁ئاي', 'دى', 'ڭ', 'لاشتۇر', 'الماي', 'ۋاتقان', 'لىقى', 'مىز', 'دىن', 'مى', 'كىن', 'تا', 'ڭ']\n",
      "[0, 2931, 413, 244, 207, 413, 72, 120, 346, 91, 1983, 137, 91, 159, 111, 108, 231, 326, 176, 342, 71, 568, 415, 1983, 137, 91, 28, 524, 4089, 2241, 3961, 74, 308, 415, 365, 551, 370, 1709, 1342, 1343, 186, 72, 369, 2380, 924, 131, 186, 72, 285, 118, 99, 1307, 1048, 860, 239, 315, 161, 139, 255, 200, 99]\n",
      "char length: 199 vs token ids: 61\n",
      "Source versus decoded:\n",
      "<PAD>ئىنسانلار ئادەملەر بىلەن ئادەم، قاسىم ھاشىمغا ‹ياخشىمۇسىز» دىدى. ھاشىم: مەن ياخشى، ئۆزىڭىزچۇ؟ دېدى. يەنە باشقا مىساللاردىن گۈزەللىك، ياخشىلىق، ئەسكىلىك، ئايدىڭلاشتۇرالمايۋاتقانلىقىمىزدىنمىكىنتاڭ\n",
      "ئىنسانلار ئادەملەر بىلەن ئادەم، قاسىم ھاشىمغا ‹ياخشىمۇسىز» دىدى. ھاشىم: مەن ياخشى، ئۆزىڭىزچۇ؟ دېدى. يەنە باشقا مىساللاردىن گۈزەللىك، ياخشىلىق، ئەسكىلىك، ئايدىڭلاشتۇرالمايۋاتقانلىقىمىزدىنمىكىنتاڭ\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, decoders, Encoding\n",
    "\n",
    "tokenizer: Tokenizer = Tokenizer.from_file(\"../../config/output_tokens.json\")\n",
    "tokenizer.decoder = decoders.Metaspace()\n",
    "\n",
    "example_text = \"<PAD>ئىنسانلار ئادەملەر بىلەن ئادەم، قاسىم ھاشىمغا ‹ياخشىمۇسىز» دىدى. ھاشىم: مەن ياخشى، ئۆزىڭىزچۇ؟ دېدى. يەنە باشقا مىساللاردىن گۈزەللىك، ياخشىلىق، ئەسكىلىك، ئايدىڭلاشتۇرالمايۋاتقانلىقىمىزدىنمىكىنتاڭ\"\n",
    "tokenized: Encoding = tokenizer.encode(example_text)\n",
    "print(tokenized.tokens)\n",
    "print(tokenized.ids)\n",
    "print(f\"char length: {len(example_text)} vs token ids: {len(tokenized.ids)}\")\n",
    "decoded: str = tokenizer.decode(tokenized.ids, skip_special_tokens=True)\n",
    "print(\"Source versus decoded:\")\n",
    "print(example_text)\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spell_correction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
